{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S394070_Report",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SilLoGOVq8Sz"
      },
      "source": [
        "# Deep Variational Models for Collaborative Filtering-based Recommender Systems\n",
        "\n",
        "## Summary Table\n",
        "| Category | Description |\n",
        "| --- | --- |\n",
        "| Problem | Deep learning provides accurate collaborative filtering models to improve recommender system results. Deep matrix factorization and their related collaborative neural networks are the state-of-art in the field; nevertheless, both models lack the necessary stochasticity to create the robust, continuous, and structured latent spaces that variational autoencoders exhibit. On the other hand, data augmentation through variational autoencoder does not provide accurate results in the collaborative filtering field due to the high sparsity of recommender systems. |\n",
        "| Hypothesis | Rating values can be better predicted when a variational latent space has been learnt, because this space covers a wider, more robust, and more representative latent area. The augmented samples will be more accurate and effective if they are generated in an inner and dense latent space rather than in a very sparse input space. |\n",
        "| Benefits | This method does not depend on the particular model used to generate the latent representation. In this way, this approach can be applied as a plugin to any current and future specific models. |\n",
        "| Solution | This models apply the variational concept to inject stochasticity in the latent space of the deep architecture, introducing the variational technique in the neural collaborative filtering field. |\n",
        "| Dataset | FilmTrust, MovieLens-1m, MyAnimeList |\n",
        "| Preprocessing | Dataset is already processed. Three fields - userid, itemid, rating. |\n",
        "| Metrics | MAE, MSE, Precision, Recall, NDCG |\n",
        "| Models | Neural Collaborative Filtering (NCF), Deep Matrix Factorization (DeepMF), Variational NCF (VNCF), Variational DeepMF (VDeepMF) |\n",
        "| Cluster | Tensorflow 2.7 |\n",
        "| Tags | VariationalAutoencoder, DeepMF, NCF |\n",
        "\n",
        "## Variational Autoencoder\n",
        "\n",
        "![A taxonomy of autoencoders. The dotted arrows denote a sampling operation. [source](https://arxiv.org/pdf/1802.05814.pdf).](https://github.com/RecoHut-Stanzas/S394070/raw/main/images/vae1.png)\n",
        "\n",
        "A taxonomy of autoencoders. The dotted arrows denote a sampling operation. [source](https://arxiv.org/pdf/1802.05814.pdf).\n",
        "\n",
        "**Variational Autoencoder (VAE)** is an unsupervised latent variable model that learns a deep representation from high-dimensional data. The idea is to encode the input as a probability distribution rather than a point estimate as in vanilla auto-encoder. Then VAE uses a decoder to reconstruct the original input by using samples from that probability distribution.\n",
        "\n",
        "![Variational Autoencoder Architecture and Loss function. [source](https://towardsdatascience.com/recommendation-system-series-part-6-the-6-variants-of-autoencoders-for-collaborative-filtering-bd7b9eae2ec7).](https://github.com/RecoHut-Stanzas/S394070/raw/main/images/vae2.png)\n",
        "\n",
        "Variational Autoencoder Architecture and Loss function. [source](https://towardsdatascience.com/recommendation-system-series-part-6-the-6-variants-of-autoencoders-for-collaborative-filtering-bd7b9eae2ec7).\n",
        "\n",
        "## Autoencoder in Recommender systems\n",
        "\n",
        "The Variational Autoencoder is a neural network that provides collaborative filtering based on implicit feedback. Specifically, it provides product recommendations based on user and item interactions. The training data for this model should contain a sequence of (user ID, item ID) pairs indicating that the specified user has interacted with the specified item.\n",
        "\n",
        "The model consists of two parts: the encoder and the decoder. The encoder transforms the vector, which contains the interactions for a specific user, into a *n*-dimensional variational distribution. We can then use this variational distribution to obtain a latent representation of a user. This latent representation is then fed into the decoder. The result is a vector of item interaction probabilities for a particular user.\n",
        "\n",
        "### AutoRec\n",
        "\n",
        "One of the earliest models that consider the collaborative filtering problem from an auto-encoder perspective is **AutoRec** from “[Autoencoders Meet Collaborative Filtering](https://users.cecs.anu.edu.au/~akmenon/papers/autorec/autorec-paper.pdf)” by Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, and Lexing Xie.\n",
        "\n",
        "### DeepRec\n",
        "\n",
        "**DeepRec** is a model created by Oleisii Kuchaiev and Boris Ginsburg from NVIDIA, as seen in “[Training Deep Autoencoders for Collaborative Filtering](https://arxiv.org/abs/1708.01715).” The model is inspired by the AutoRec model described above, with several important distinctions:\n",
        "\n",
        "- The network is much deeper.\n",
        "- The model uses “scaled exponential linear units” (SELUs).\n",
        "- The dropout rate is high.\n",
        "- The authors use iterative output re-feeding during training.\n",
        "\n",
        "### Collaborative Denoising Autoencoders\n",
        "\n",
        "[“Collaborative Denoising Autoencoders for Top-N Recommender Systems](https://alicezheng.org/papers/wsdm16-cdae.pdf)” by Yao Wu, Christopher DuBois, Alice Zheng, and Martin Ester is a neural network with one hidden layer. Compared to AutoRec and DeepRec, **CDAE** has the following differences:\n",
        "\n",
        "- The input of CDAE is not user-item ratings, but partially observed implicit feedback r (user’s item preference). If a user likes a movie, the corresponding entry value is 1, otherwise 0.\n",
        "- Unlike the previous two models that are used for rating prediction, CDAE is principally used for ranking prediction (also called Top-N preference recommendations).\n",
        "\n",
        "### Multinomial Variational Autoencoders\n",
        "\n",
        "One of the most influential papers in this discussion is “[Variational Autoencoders for Collaborative Filtering](https://arxiv.org/abs/1802.05814)” by Dawen Liang, Rahul Krishnan, Matthew Hoffman, and Tony Jebara from Netflix. It proposes a variant of VAE for recommendation with implicit data. In particular, the authors introduced **a principled Bayesian inference approach** to estimate model parameters and show favorable results than commonly used likelihood functions.\n",
        "\n",
        "### Sequential Variational Autoencoders\n",
        "\n",
        "In “[Sequential Variational Auto-encoders for Collaborative Filtering](https://arxiv.org/abs/1811.09975),” Noveen Sachdeva, Giuseppe Manco, Ettore Ritacco, and Vikram Pudi propose an extension of MultVAE by exploring the rich information present in the past preference history. They introduce **a recurrent version of MultVAE**, where instead of passing a subset of the whole history regardless of temporal dependencies, they pass the consumption sequence subset through a recurrent neural network. They show that **handling temporal information** is crucial for improving the accuracy of VAE.\n",
        "\n",
        "### Embarrassingly Shallow Autoencoders\n",
        "\n",
        "Harald Steck’s “[Embarrassingly Shallow Autoencoders for Sparse Data](https://arxiv.org/abs/1905.03375)” is a fascinating one that I want to bring into this discussion. The motivation here is that, according to his literature review, *deep models with a large number of hidden layers typically do* ***not*** *obtain a notable improvement in ranking accuracy in collaborative filtering, compared to ‘deep’ models with only one, two, or three hidden layers.* This is a stark contrast to other areas like NLP or computer vision.\n",
        "\n",
        "## Model Architecture\n",
        "<p><center><figure><img src='https://github.com/RecoHut-Stanzas/S394070/blob/main/images/model.png?raw=true'><figcaption><i>Proposed VDeepMF architecture. The NCF architecture will have identical ‘Embedding’ and ‘Variational’ layers to the VDeepMF one; it will just replace the ‘Dot’ layer for a ‘Concatenate’ layer, followed by an MLP.</i></figcaption></figure></center></p>\n",
        "\n",
        "## Process Flow\n",
        "<img src='https://raw.githubusercontent.com/RecoHut-Stanzas/S394070/main/images/flow.svg'>\n",
        "\n",
        "## Tutorials\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RecoHut-Stanzas/S394070/)\n",
        "\n",
        "### VDeepMF and its variants on FilmTrust Dataset in Tensorflow\n",
        "\n",
        "[direct link to the notebook →](https://github.com/RecoHut-Stanzas/S394070/blob/main/nbs/Deep_Variational_Models_on_FilmTrust%2C_ML_1m%2C_and_MyAnimeList_Dataset_in_Tensorflow.ipynb)\n",
        "\n",
        "## Links & References\n",
        "\n",
        "1. https://arxiv.org/abs/2107.12677v1\n",
        "2. https://github.com/KNODIS-Research-Group/deep-variational-models-for-collaborative-filtering"
      ]
    }
  ]
}